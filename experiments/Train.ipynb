{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064e2d60",
   "metadata": {},
   "source": [
    "# INDEX\n",
    "* [Functions](#Functions)\n",
    "* [Configuration](#Configuration)\n",
    "* [Preprocess training data](#Preprocess-training-data)\n",
    "* [Train](#Train)\n",
    "* [Test model](#Test-model)\n",
    "    * [Predict](#Predict)\n",
    "    * [Explore dataset](#Explore-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481d404",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80c4f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') #append a relative path to the top package to the search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda92a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load libtrain.py\n",
    "import datetime\n",
    "import functools\n",
    "import json\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "from typing import Dict, List\n",
    "\n",
    "import dacite\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from robotoff.taxonomy import Taxonomy\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "\n",
    "import settings\n",
    "from category_classification.data_utils import (\n",
    "    TFTransformer,\n",
    "    create_tf_dataset,\n",
    "    load_dataframe,\n",
    ")\n",
    "from category_classification.models import (\n",
    "    KerasPreprocessing,\n",
    "    build_model,\n",
    "    construct_preprocessing,\n",
    "    to_serving_model,\n",
    ")\n",
    "\n",
    "from category_classification.config import Config\n",
    "\n",
    "from utils.io import (\n",
    "    copy_category_taxonomy,\n",
    "    save_category_vocabulary,\n",
    "    save_config,\n",
    "    save_json,\n",
    ")\n",
    "from utils.metrics import evaluation_report\n",
    "\n",
    "def create_model(config: Config, preprocess: KerasPreprocessing) -> keras.Model:\n",
    "    model = build_model(config.model_config, preprocess)\n",
    "    loss_fn = keras.losses.BinaryCrossentropy(\n",
    "        label_smoothing=config.train_config.label_smoothing\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=config.train_config.lr)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_fn,\n",
    "        metrics=[\"binary_accuracy\", \"Precision\", \"Recall\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class TBCallback(callbacks.TensorBoard):\n",
    "    \"\"\"Get around a bug where you cannot use the TensorBoard callback with the StringLookup layers\n",
    "    - https://github.com/tensorflow/tensorboard/issues/4530#issuecomment-783318292\"\"\"\n",
    "\n",
    "    def _log_weights(self, epoch):\n",
    "        with self._train_writer.as_default():\n",
    "            with summary_ops_v2.always_record_summaries():\n",
    "                for layer in self.model.layers:\n",
    "                    for weight in layer.weights:\n",
    "                        if hasattr(weight, \"name\"):\n",
    "                            weight_name = weight.name.replace(\":\", \"_\")\n",
    "                            summary_ops_v2.histogram(weight_name, weight, step=epoch)\n",
    "                            if self.write_images:\n",
    "                                self._log_weight_as_image(weight, weight_name, epoch)\n",
    "                self._train_writer.flush()\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: keras.Model,\n",
    "    save_dir: pathlib.Path,\n",
    "    config: Config,\n",
    "    category_vocab: List[str],\n",
    "):\n",
    "    print(\"Starting training...\")\n",
    "    temporary_log_dir = pathlib.Path(tempfile.mkdtemp())\n",
    "    print(\"Temporary log directory: {}\".format(temporary_log_dir))\n",
    "\n",
    "    tf_transformer = TFTransformer(category_vocab)\n",
    "\n",
    "    train = create_tf_dataset(\"train\", config.train_config.batch_size, tf_transformer)\n",
    "    val = create_tf_dataset(\"val\", config.train_config.batch_size, tf_transformer)\n",
    "\n",
    "    history=model.fit(train,\n",
    "        epochs= config.train_config.epochs,\n",
    "        validation_data=val,\n",
    "        callbacks=[\n",
    "            callbacks.TerminateOnNaN(),\n",
    "            callbacks.ModelCheckpoint(\n",
    "                filepath=str(save_dir / \"weights.{epoch:02d}-{val_loss:.4f}\"),\n",
    "                monitor=\"val_loss\",\n",
    "                save_best_only=True,\n",
    "                save_format='tf',\n",
    "            ),\n",
    "            #TBCallback(log_dir=str(temporary_log_dir), histogram_freq=1),\n",
    "            callbacks.EarlyStopping(monitor=\"val_loss\", patience=4),\n",
    "            #callbacks.CSVLogger(str(save_dir / \"training.csv\")),\n",
    "            callbacks.History()\n",
    "        ],\n",
    "    )\n",
    "    print(\"Training ended\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfc7ed",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a92c3dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load config json\n",
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "with open('../config.json') as json_file:\n",
    "    json_config = json.load(json_file)\n",
    "json_config \n",
    "\n",
    "config=dacite.from_dict(Config, json_config)\n",
    "model_config=config.model_config\n",
    "\n",
    "output_dir:pathlib.Path = pathlib.Path(\"../models\")\n",
    "replicates = 1\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92b58e",
   "metadata": {},
   "source": [
    "# Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c68cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 09:23:20.877531: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 09:23:21.123901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed training data\n",
      "CPU times: user 4min 37s, sys: 6.47 s, total: 4min 43s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keras_preprocess = construct_preprocessing(\n",
    "    model_config.category_min_count,\n",
    "    model_config.ingredient_min_count,\n",
    "    model_config.product_name_max_tokens,\n",
    "    model_config.product_name_max_length,\n",
    "    load_dataframe(\"train\"),\n",
    ")\n",
    "print(\"Pre-processed training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c2786",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb0c0a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training repeat 0\n",
      "Starting training...\n",
      "Temporary log directory: /var/folders/c7/w4lf4cp91_j_p3dxm9w00rmh0000gn/T/tmp2o2lcebx\n",
      "Epoch 1/50\n",
      "5465/5465 [==============================] - 1408s 257ms/step - loss: 0.0081 - binary_accuracy: 0.9985 - precision: 0.2376 - recall: 0.0929 - val_loss: 0.0040 - val_binary_accuracy: 0.9990 - val_precision: 0.8507 - val_recall: 0.2642\n",
      "INFO:tensorflow:Assets written to: models/weights.01-0.0040/assets\n",
      "Epoch 2/50\n",
      "5465/5465 [==============================] - 1451s 265ms/step - loss: 0.0033 - binary_accuracy: 0.9992 - precision: 0.8171 - recall: 0.4194 - val_loss: 0.0023 - val_binary_accuracy: 0.9994 - val_precision: 0.8848 - val_recall: 0.5584\n",
      "INFO:tensorflow:Assets written to: models/weights.02-0.0023/assets\n",
      "Epoch 3/50\n",
      "5465/5465 [==============================] - 3169s 580ms/step - loss: 0.0022 - binary_accuracy: 0.9994 - precision: 0.8460 - recall: 0.5942 - val_loss: 0.0018 - val_binary_accuracy: 0.9995 - val_precision: 0.8872 - val_recall: 0.6674\n",
      "INFO:tensorflow:Assets written to: models/weights.03-0.0018/assets\n",
      "Epoch 4/50\n",
      "5465/5465 [==============================] - 3106s 568ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - precision: 0.8577 - recall: 0.6631 - val_loss: 0.0016 - val_binary_accuracy: 0.9995 - val_precision: 0.8895 - val_recall: 0.7112\n",
      "INFO:tensorflow:Assets written to: models/weights.04-0.0016/assets\n",
      "Epoch 5/50\n",
      "5465/5465 [==============================] - 5186s 949ms/step - loss: 0.0017 - binary_accuracy: 0.9995 - precision: 0.8647 - recall: 0.6984 - val_loss: 0.0015 - val_binary_accuracy: 0.9996 - val_precision: 0.8896 - val_recall: 0.7336\n",
      "INFO:tensorflow:Assets written to: models/weights.05-0.0015/assets\n",
      "Epoch 6/50\n",
      "5465/5465 [==============================] - 1603s 293ms/step - loss: 0.0016 - binary_accuracy: 0.9995 - precision: 0.8690 - recall: 0.7202 - val_loss: 0.0015 - val_binary_accuracy: 0.9996 - val_precision: 0.8904 - val_recall: 0.7460\n",
      "INFO:tensorflow:Assets written to: models/weights.06-0.0015/assets\n",
      "Epoch 7/50\n",
      "5465/5465 [==============================] - 1373s 251ms/step - loss: 0.0015 - binary_accuracy: 0.9995 - precision: 0.8722 - recall: 0.7361 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8881 - val_recall: 0.7600\n",
      "INFO:tensorflow:Assets written to: models/weights.07-0.0014/assets\n",
      "Epoch 8/50\n",
      "5465/5465 [==============================] - 1467s 268ms/step - loss: 0.0014 - binary_accuracy: 0.9995 - precision: 0.8748 - recall: 0.7478 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8901 - val_recall: 0.7656\n",
      "INFO:tensorflow:Assets written to: models/weights.08-0.0014/assets\n",
      "Epoch 9/50\n",
      "5465/5465 [==============================] - 1477s 270ms/step - loss: 0.0014 - binary_accuracy: 0.9995 - precision: 0.8770 - recall: 0.7574 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8903 - val_recall: 0.7712\n",
      "INFO:tensorflow:Assets written to: models/weights.09-0.0014/assets\n",
      "Epoch 10/50\n",
      "5465/5465 [==============================] - 1352s 247ms/step - loss: 0.0014 - binary_accuracy: 0.9995 - precision: 0.8791 - recall: 0.7649 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8887 - val_recall: 0.7766\n",
      "INFO:tensorflow:Assets written to: models/weights.10-0.0014/assets\n",
      "Epoch 11/50\n",
      "5465/5465 [==============================] - 1383s 253ms/step - loss: 0.0013 - binary_accuracy: 0.9996 - precision: 0.8806 - recall: 0.7709 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8898 - val_recall: 0.7785\n",
      "INFO:tensorflow:Assets written to: models/weights.11-0.0014/assets\n",
      "Epoch 12/50\n",
      "5465/5465 [==============================] - 1603s 293ms/step - loss: 0.0013 - binary_accuracy: 0.9996 - precision: 0.8819 - recall: 0.7763 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8891 - val_recall: 0.7819\n",
      "INFO:tensorflow:Assets written to: models/weights.12-0.0014/assets\n",
      "Epoch 13/50\n",
      "5465/5465 [==============================] - 1555s 285ms/step - loss: 0.0013 - binary_accuracy: 0.9996 - precision: 0.8830 - recall: 0.7808 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8861 - val_recall: 0.7865\n",
      "INFO:tensorflow:Assets written to: models/weights.13-0.0014/assets\n",
      "Epoch 14/50\n",
      "5465/5465 [==============================] - 1743s 319ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.8843 - recall: 0.7850 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8893 - val_recall: 0.7856\n",
      "Epoch 15/50\n",
      "5465/5465 [==============================] - 1490s 273ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.8853 - recall: 0.7884 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8879 - val_recall: 0.7889\n",
      "Epoch 16/50\n",
      "5465/5465 [==============================] - 1564s 286ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.8863 - recall: 0.7914 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8889 - val_recall: 0.7894\n",
      "Epoch 17/50\n",
      "5465/5465 [==============================] - 1359s 249ms/step - loss: 0.0012 - binary_accuracy: 0.9996 - precision: 0.8868 - recall: 0.7944 - val_loss: 0.0014 - val_binary_accuracy: 0.9996 - val_precision: 0.8884 - val_recall: 0.7902\n",
      "Training ended\n",
      "CPU times: user 18h 35min 10s, sys: 5h 38min 39s, total: 1d 13min 50s\n",
      "Wall time: 8h 59min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if replicates == 1:\n",
    "    save_dirs = [output_dir]\n",
    "else:\n",
    "    save_dirs = [output_dir / str(i) for i in range(replicates)]\n",
    "\n",
    "for i, save_dir in enumerate(save_dirs):\n",
    "    model = create_model(config, keras_preprocess)\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    config.train_config.start_datetime = str(datetime.datetime.utcnow())\n",
    "    print(f\"Starting training repeat {i}\")\n",
    "\n",
    "    save_config(config, save_dir)\n",
    "    copy_category_taxonomy(settings.CATEGORY_TAXONOMY_PATH, save_dir)\n",
    "    save_category_vocabulary(keras_preprocess.category_vocab, save_dir)\n",
    "\n",
    "    history=train(\n",
    "        model,\n",
    "        save_dir,\n",
    "        config,\n",
    "        keras_preprocess.category_vocab,\n",
    "    )\n",
    "\n",
    "    config.train_config.end_datetime = str(datetime.datetime.utcnow())\n",
    "    save_config(config, save_dir)\n",
    "    config.train_config.start_datetime = None\n",
    "    config.train_config.end_datetime = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a29603",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdba60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "model=keras.models.load_model('../models/base/saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cff4364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vocab=keras_preprocess.category_vocab\n",
    "tf_transformer = TFTransformer(category_vocab)\n",
    "\n",
    "# Train & validation Dataset => investigate on characteristics of the source\n",
    "traindata = create_tf_dataset(\"train\", config.train_config.batch_size, tf_transformer)\n",
    "valdata = create_tf_dataset(\"val\", config.train_config.batch_size, tf_transformer)\n",
    "testdata = create_tf_dataset(\"test\", config.train_config.batch_size, tf_transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d279f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaddedBatchDataset shapes: (((None, None), (None,)), (None, 3969)), types: ((tf.string, tf.string), tf.int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47d29ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaddedBatchDataset shapes: (((None, None), (None,)), (None, 3969)), types: ((tf.string, tf.string), tf.int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee83647",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcb0f069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 18.7 s, total: 1min 52s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_val = model.predict(valdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c76368ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 17.7 s, total: 1min 58s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_test=model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a90553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87434, 3969),\n",
       " array([[1.1422783e-02, 2.9106607e-08, 1.8616578e-06, ..., 1.3573744e-10,\n",
       "         1.6678333e-09, 1.1400034e-07],\n",
       "        [1.9434567e-05, 6.0262022e-09, 4.3250511e-06, ..., 9.5710753e-18,\n",
       "         1.8540440e-14, 8.8534751e-13],\n",
       "        [9.8198652e-04, 5.3054283e-10, 1.0436243e-08, ..., 1.4927385e-14,\n",
       "         1.0176477e-12, 1.2061078e-12],\n",
       "        ...,\n",
       "        [7.5667924e-01, 1.3700799e-11, 2.1688192e-12, ..., 2.8258068e-18,\n",
       "         2.3219839e-16, 3.5128806e-13],\n",
       "        [2.4676323e-04, 4.8964339e-14, 6.0147217e-12, ..., 1.8756643e-16,\n",
       "         2.5486165e-15, 1.1011587e-15],\n",
       "        [1.1568367e-03, 1.1596524e-05, 5.4461787e-05, ..., 1.3919157e-11,\n",
       "         2.4204746e-13, 6.0214539e-10]], dtype=float32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val.shape, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c7d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2839634e-05, 2.3829339e-10, 1.6613468e-09, ..., 1.5564917e-11,\n",
       "        3.6129602e-10, 2.1100532e-12],\n",
       "       [1.0495579e-01, 2.0508166e-09, 2.3943665e-09, ..., 1.3911613e-08,\n",
       "        1.0217517e-08, 3.8321792e-07],\n",
       "       [1.9471225e-05, 6.9090309e-14, 3.4578873e-15, ..., 1.7461139e-10,\n",
       "        1.5341870e-09, 3.1657670e-11],\n",
       "       ...,\n",
       "       [3.8076937e-03, 1.6157297e-06, 6.6229504e-06, ..., 1.5495643e-06,\n",
       "        8.5407401e-06, 3.0552085e-06],\n",
       "       [1.3194382e-03, 1.6692168e-10, 3.1451568e-09, ..., 4.1883336e-14,\n",
       "        4.0008542e-17, 5.4479357e-14],\n",
       "       [1.3995171e-04, 4.6972590e-09, 6.7628537e-07, ..., 2.1551901e-16,\n",
       "        4.0634002e-10, 5.0259403e-15]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef80a060",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# accuracy_score is for a classification model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/off/lib/python3.8/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/off/lib/python3.8/site-packages/sklearn/metrics/_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    107\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_score is for a classification model\n",
    "accuracy_score(y_pred_test,y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236de988",
   "metadata": {},
   "source": [
    "Error occurs due to continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c04e3",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5cf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from robotoff.utils import gzip_jsonl_iter\n",
    "import pathlib\n",
    "\n",
    "import settings\n",
    "from typing import Any, Callable, Dict, Iterable, Optional, List\n",
    "\n",
    "def create_dataframe(split: str, lang: str) -> pd.DataFrame:\n",
    "     if split not in (\"train\", \"test\", \"val\"):\n",
    "         raise ValueError(\"split must be either 'train', 'test' or 'val'\")\n",
    "\n",
    "     file_name = \"category_{}.{}.jsonl.gz\".format(lang, split)\n",
    "     full_path = settings.DATA_DIR / file_name\n",
    "     return pd.DataFrame(iter_product(full_path))\n",
    "\n",
    "def count_categories(df: pd.DataFrame) -> Dict:\n",
    "    categories_count = defaultdict(int)\n",
    "\n",
    "    for categories in df.categories_tags:\n",
    "        for category in categories:\n",
    "            categories_count[category] += 1\n",
    "\n",
    "    return categories_count\n",
    "\n",
    "def iter_product(data_path: pathlib.Path):\n",
    "    for product in gzip_jsonl_iter(data_path):\n",
    "        product.pop(\"images\", None)\n",
    "\n",
    "        if \"nutriments\" in product:\n",
    "            nutriments = product[\"nutriments\"] or {}\n",
    "\n",
    "        yield product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1987f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = create_dataframe(\"train\", \"xx\")\n",
    "test_ds = create_dataframe(\"test\", \"xx\")\n",
    "val_ds = create_dataframe(\"val\", \"xx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbc22c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87434, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bd0764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>nutriments</th>\n",
       "      <th>product_name</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>ingredient_tags</th>\n",
       "      <th>known_ingredient_tags</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47994</th>\n",
       "      <td>0852681918989</td>\n",
       "      <td>{'cholesterol_100g': 0.071, 'iron_unit': 'mg',...</td>\n",
       "      <td>Organic Double Chocolate Cookies</td>\n",
       "      <td>[en:biscuits-and-cakes, en:biscuits, en:sweet-...</td>\n",
       "      <td>[en:wheat-flour, en:cereal, en:flour, en:wheat...</td>\n",
       "      <td>[en:wheat-flour, en:cereal, en:flour, en:wheat...</td>\n",
       "      <td>Organic wheat flour, organic semi-sweet chocol...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54907</th>\n",
       "      <td>0761088191812</td>\n",
       "      <td>{'energy_value': 69, 'energy-kcal_serving': 16...</td>\n",
       "      <td>Basil Chicken Chili With Beans</td>\n",
       "      <td>[en:stews, en:meals]</td>\n",
       "      <td>[en:chicken-broth, en:poultry, en:chicken, en:...</td>\n",
       "      <td>[en:chicken-broth, en:poultry, en:chicken, en:...</td>\n",
       "      <td>Chicken stock (water, spice, garlic, salt, bla...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25595</th>\n",
       "      <td>00853163</td>\n",
       "      <td>{'sodium_unit': 'g', 'sugars_100g': 46.4, 'pro...</td>\n",
       "      <td>Sicilian lemon curd</td>\n",
       "      <td>[en:fruit-curds, en:spreads, en:lemon-curds, e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22122</th>\n",
       "      <td>0074734115330</td>\n",
       "      <td>{'nutrition-score-fr': 12, 'fat': 13.33, 'ener...</td>\n",
       "      <td>Crackers</td>\n",
       "      <td>[en:biscuits-and-cakes]</td>\n",
       "      <td>[en:wheat-flour, en:cereal, en:flour, en:wheat...</td>\n",
       "      <td>[en:wheat-flour, en:cereal, en:flour, en:wheat...</td>\n",
       "      <td>Enriched bleached wheat flour (wheat flour, ni...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77128</th>\n",
       "      <td>5400111272658</td>\n",
       "      <td>{'nutrition-score-fr_100g': 13, 'sugars_unit':...</td>\n",
       "      <td>Cornet de glace vanille chocolat</td>\n",
       "      <td>[en:desserts, en:ice-creams, en:ice-creams-and...</td>\n",
       "      <td>[en:sugar, en:skimmed-milk, en:dairy, en:milk,...</td>\n",
       "      <td>[en:sugar, en:skimmed-milk, en:dairy, en:milk,...</td>\n",
       "      <td>Sucre, lait écrémé, farine de blé, crème fraîc...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77191</th>\n",
       "      <td>3274664099282</td>\n",
       "      <td>{'carbohydrates': 36.5, 'energy-kcal': 261, 's...</td>\n",
       "      <td>Façon Citron Meringué</td>\n",
       "      <td>[en:ice-creams-and-sorbets, en:desserts, en:fr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41673</th>\n",
       "      <td>0077300505016</td>\n",
       "      <td>{'nova-group_serving': 1, 'carbohydrates_unit'...</td>\n",
       "      <td>Enriched Long Grain White Rice</td>\n",
       "      <td>[en:seeds, en:plant-based-foods-and-beverages,...</td>\n",
       "      <td>[en:long-grain-enriched-milled-rice, en:ferric...</td>\n",
       "      <td>[en:ferric-orthophosphate, en:minerals, en:iro...</td>\n",
       "      <td>Long Grain Enriched Milled Rice, Ferric Orthop...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84576</th>\n",
       "      <td>0078000029000</td>\n",
       "      <td>{'sodium_serving': 0, 'fat_100g': 0, 'carbohyd...</td>\n",
       "      <td>Sparkling water beverage, black cherry</td>\n",
       "      <td>[en:waters, en:beverages]</td>\n",
       "      <td>[en:carbonated-water, en:water, en:natural-fla...</td>\n",
       "      <td>[en:carbonated-water, en:water, en:natural-fla...</td>\n",
       "      <td>Carbonated water, natural flavors.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62737</th>\n",
       "      <td>0035826089021</td>\n",
       "      <td>{'proteins_100g': 0, 'energy_serving': 20.9, '...</td>\n",
       "      <td>Food lion, on-the-go drink mix, lemonade</td>\n",
       "      <td>[en:dried-products, en:dried-products-to-be-re...</td>\n",
       "      <td>[en:e330, en:potassium, en:minerals, en:sodium...</td>\n",
       "      <td>[en:e330, en:potassium, en:minerals, en:sodium...</td>\n",
       "      <td>Citric acid, potassium and sodium citrate, nat...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63139</th>\n",
       "      <td>5411788038836</td>\n",
       "      <td>{'nutrition-score-fr_100g': 6, 'sugars_unit': ...</td>\n",
       "      <td>Umeboshi Past</td>\n",
       "      <td>[en:fruits-and-vegetables-based-foods, en:plan...</td>\n",
       "      <td>[fr:umeboshi, fr:feuilles-de-shiso, en:sea-sal...</td>\n",
       "      <td>[en:sea-salt, en:salt]</td>\n",
       "      <td>Umeboshi (Prunus mume), feuilles de shiso (Per...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                code                                         nutriments  \\\n",
       "47994  0852681918989  {'cholesterol_100g': 0.071, 'iron_unit': 'mg',...   \n",
       "54907  0761088191812  {'energy_value': 69, 'energy-kcal_serving': 16...   \n",
       "25595       00853163  {'sodium_unit': 'g', 'sugars_100g': 46.4, 'pro...   \n",
       "22122  0074734115330  {'nutrition-score-fr': 12, 'fat': 13.33, 'ener...   \n",
       "77128  5400111272658  {'nutrition-score-fr_100g': 13, 'sugars_unit':...   \n",
       "77191  3274664099282  {'carbohydrates': 36.5, 'energy-kcal': 261, 's...   \n",
       "41673  0077300505016  {'nova-group_serving': 1, 'carbohydrates_unit'...   \n",
       "84576  0078000029000  {'sodium_serving': 0, 'fat_100g': 0, 'carbohyd...   \n",
       "62737  0035826089021  {'proteins_100g': 0, 'energy_serving': 20.9, '...   \n",
       "63139  5411788038836  {'nutrition-score-fr_100g': 6, 'sugars_unit': ...   \n",
       "\n",
       "                                   product_name  \\\n",
       "47994          Organic Double Chocolate Cookies   \n",
       "54907            Basil Chicken Chili With Beans   \n",
       "25595                       Sicilian lemon curd   \n",
       "22122                                  Crackers   \n",
       "77128          Cornet de glace vanille chocolat   \n",
       "77191                     Façon Citron Meringué   \n",
       "41673            Enriched Long Grain White Rice   \n",
       "84576    Sparkling water beverage, black cherry   \n",
       "62737  Food lion, on-the-go drink mix, lemonade   \n",
       "63139                             Umeboshi Past   \n",
       "\n",
       "                                         categories_tags  \\\n",
       "47994  [en:biscuits-and-cakes, en:biscuits, en:sweet-...   \n",
       "54907                               [en:stews, en:meals]   \n",
       "25595  [en:fruit-curds, en:spreads, en:lemon-curds, e...   \n",
       "22122                            [en:biscuits-and-cakes]   \n",
       "77128  [en:desserts, en:ice-creams, en:ice-creams-and...   \n",
       "77191  [en:ice-creams-and-sorbets, en:desserts, en:fr...   \n",
       "41673  [en:seeds, en:plant-based-foods-and-beverages,...   \n",
       "84576                          [en:waters, en:beverages]   \n",
       "62737  [en:dried-products, en:dried-products-to-be-re...   \n",
       "63139  [en:fruits-and-vegetables-based-foods, en:plan...   \n",
       "\n",
       "                                         ingredient_tags  \\\n",
       "47994  [en:wheat-flour, en:cereal, en:flour, en:wheat...   \n",
       "54907  [en:chicken-broth, en:poultry, en:chicken, en:...   \n",
       "25595                                                 []   \n",
       "22122  [en:wheat-flour, en:cereal, en:flour, en:wheat...   \n",
       "77128  [en:sugar, en:skimmed-milk, en:dairy, en:milk,...   \n",
       "77191                                                 []   \n",
       "41673  [en:long-grain-enriched-milled-rice, en:ferric...   \n",
       "84576  [en:carbonated-water, en:water, en:natural-fla...   \n",
       "62737  [en:e330, en:potassium, en:minerals, en:sodium...   \n",
       "63139  [fr:umeboshi, fr:feuilles-de-shiso, en:sea-sal...   \n",
       "\n",
       "                                   known_ingredient_tags  \\\n",
       "47994  [en:wheat-flour, en:cereal, en:flour, en:wheat...   \n",
       "54907  [en:chicken-broth, en:poultry, en:chicken, en:...   \n",
       "25595                                                 []   \n",
       "22122  [en:wheat-flour, en:cereal, en:flour, en:wheat...   \n",
       "77128  [en:sugar, en:skimmed-milk, en:dairy, en:milk,...   \n",
       "77191                                                 []   \n",
       "41673  [en:ferric-orthophosphate, en:minerals, en:iro...   \n",
       "84576  [en:carbonated-water, en:water, en:natural-fla...   \n",
       "62737  [en:e330, en:potassium, en:minerals, en:sodium...   \n",
       "63139                             [en:sea-salt, en:salt]   \n",
       "\n",
       "                                        ingredients_text lang  \n",
       "47994  Organic wheat flour, organic semi-sweet chocol...   en  \n",
       "54907  Chicken stock (water, spice, garlic, salt, bla...   en  \n",
       "25595                                               None   fr  \n",
       "22122  Enriched bleached wheat flour (wheat flour, ni...   en  \n",
       "77128  Sucre, lait écrémé, farine de blé, crème fraîc...   fr  \n",
       "77191                                               None   fr  \n",
       "41673  Long Grain Enriched Milled Rice, Ferric Orthop...   en  \n",
       "84576                 Carbonated water, natural flavors.   en  \n",
       "62737  Citric acid, potassium and sodium citrate, nat...   en  \n",
       "63139  Umeboshi (Prunus mume), feuilles de shiso (Per...   fr  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.sample(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86ceb2b9",
   "metadata": {},
   "source": [
    " # test\n",
    " predicted_categories_nodes = [taxonomy[c] for c in predicted_categories]\n",
    "    true_categories_nodes = [taxonomy[c] for c in true_categories]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
